{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4474ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain faiss-cpu langchain-huggingface sentence-transformers tqdm pypdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e2acf1",
   "metadata": {},
   "source": [
    "## Cài đặt & Nhập thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16675292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,199 - INFO - Đã nhập thư viện (sử dụng FAISS) và cấu hình logging.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Cài đặt các thư viện nếu cần thiết (chạy một lần)\n",
    "# !pip install -U langchain faiss-cpu langchain-huggingface sentence-transformers tqdm pypdf\n",
    "\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path # Để xử lý đường dẫn file tốt hơn\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm # Sử dụng tqdm.notebook cho Jupyter\n",
    "\n",
    "# Các thành phần LangChain\n",
    "# Cố gắng import FAISS từ các vị trí phổ biến\n",
    "try:\n",
    "    # Thử import từ vị trí mới hơn trước (nếu đã cài langchain-faiss)\n",
    "    from langchain_faiss import FAISS\n",
    "    logging.info(\"Đã import FAISS từ langchain_faiss\")\n",
    "except ImportError:\n",
    "    try:\n",
    "         # Nếu không được, thử import từ community (phiên bản cũ hơn)\n",
    "         from langchain_community.vectorstores import FAISS\n",
    "         logging.info(\"Đã import FAISS từ langchain_community.vectorstores (có thể đã cũ)\")\n",
    "    except ImportError:\n",
    "         logging.error(\"Không thể import FAISS. Hãy cài đặt 'faiss-cpu' hoặc 'faiss-gpu' và 'langchain-faiss' (nếu cần).\")\n",
    "         FAISS = None # Đặt là None nếu không import được\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document # Import cập nhật\n",
    "\n",
    "# Thiết lập Logging (ghi log) - Chạy một lần để cấu hình\n",
    "# Xóa các handler cũ nếu chạy lại cell này nhiều lần để tránh log trùng lặp\n",
    "root_logger = logging.getLogger()\n",
    "if root_logger.hasHandlers():\n",
    "    for handler in root_logger.handlers[:]: # Lặp qua bản sao của list\n",
    "        handler.close()\n",
    "        root_logger.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, # Mức độ log (INFO, WARNING, ERROR)\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', # Định dạng log\n",
    "                    handlers=[logging.FileHandler(\"processing_log_vi_jupyter_faiss_final.txt\", mode='w', encoding='utf-8'), # Ghi vào file\n",
    "                              logging.StreamHandler()]) # Hiển thị trên console\n",
    "\n",
    "logging.info(\"Đã nhập thư viện (sử dụng FAISS) và cấu hình logging.\")\n",
    "\n",
    "# Kiểm tra lại import FAISS\n",
    "if FAISS is None:\n",
    "    logging.error(\"Import FAISS thất bại. Các ô tiếp theo liên quan đến FAISS sẽ không hoạt động.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e441b",
   "metadata": {},
   "source": [
    "## Cấu hình Các tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc655de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,319 - INFO - Đã thiết lập các tham số cấu hình.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File dữ liệu JSON: data_vbpl_boyte_full_details.json\n",
      "Thư mục lưu Index FAISS: db_faiss_phapluat_yte_full_final\n",
      "Model Embedding: bkai-foundation-models/vietnamese-bi-encoder\n",
      "Load index FAISS nếu tồn tại: True\n"
     ]
    }
   ],
   "source": [
    "# --- Cấu hình ---\n",
    "JSON_FILE_PATH = Path(\"data_vbpl_boyte_full_details.json\") # <<== QUAY LẠI DÙNG FILE PATH\n",
    "PERSIST_DIRECTORY = Path(\"db_faiss_phapluat_yte_full_final\") # <<== Thư mục lưu index FAISS cho bộ đầy đủ\n",
    "COLLECTION_NAME = 'vanban_phapluat_yte_full_faiss_final' # Tên logic\n",
    "\n",
    "MODEL_NAME = \"bkai-foundation-models/vietnamese-bi-encoder\" # \n",
    "# MODEL_NAME = \"keepitreal/vietnamese-sbert\" # <<== Hoặc thử model này\n",
    "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "CHUNK_SIZE = 1000 # Số ký tự tối đa mỗi đoạn (chunk)\n",
    "CHUNK_OVERLAP = 150 # Số ký tự chồng lấn giữa các đoạn\n",
    "# Các dấu phân tách được tinh chỉnh\n",
    "SEPARATORS = [\n",
    "    \"\\nChương \", \"\\nMục \", \"\\nĐiều \",                 # Các yếu tố cấu trúc\n",
    "    \"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \" \", \"\"        # Đoạn văn, câu, từ\n",
    "]\n",
    "# Biến để kiểm soát việc có tải và thêm vào index cũ không, hay tạo mới hoàn toàn\n",
    "LOAD_EXISTING_FAISS_INDEX = True # Đặt là False nếu muốn luôn tạo index mới và ghi đè\n",
    "\n",
    "logging.info(\"Đã thiết lập các tham số cấu hình.\")\n",
    "print(f\"File dữ liệu JSON: {JSON_FILE_PATH}\")\n",
    "print(f\"Thư mục lưu Index FAISS: {PERSIST_DIRECTORY}\")\n",
    "print(f\"Model Embedding: {MODEL_NAME}\")\n",
    "print(f\"Load index FAISS nếu tồn tại: {LOAD_EXISTING_FAISS_INDEX}\")\n",
    "\n",
    "# Tạo thư mục lưu trữ nếu chưa có\n",
    "PERSIST_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "faiss_index_path = str(PERSIST_DIRECTORY) # Đường dẫn thư mục cho FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2694379",
   "metadata": {},
   "source": [
    "## Tải Dữ liệu JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4033ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,424 - INFO - Đã định nghĩa hàm load_json_data.\n"
     ]
    }
   ],
   "source": [
    "def load_json_data(file_path: Path) -> list:\n",
    "    \"\"\"Tải dữ liệu từ file JSON.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        logging.error(f\"Không tìm thấy file: {file_path}\")\n",
    "        return []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            logging.info(f\"Đã tải thành công {len(data)} văn bản từ {file_path}\")\n",
    "            return data\n",
    "        else:\n",
    "            logging.error(f\"Lỗi: File {file_path} không chứa một danh sách JSON.\")\n",
    "            return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Lỗi: File {file_path} không phải là định dạng JSON hợp lệ. {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi không xác định khi đọc file {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "logging.info(\"Đã định nghĩa hàm load_json_data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b123172",
   "metadata": {},
   "source": [
    "## Phân tích Mã Định danh Văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94856eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,478 - INFO - Đã định nghĩa hàm parse_document_id.\n"
     ]
    }
   ],
   "source": [
    "def parse_document_id(ten_van_ban: str, noi_dung: str) -> str:\n",
    "    \"\"\"Trích xuất số hiệu/mã định danh chuẩn của văn bản.\"\"\"\n",
    "    # Thử phân tích từ TenVanBan trước\n",
    "    match = re.search(r\"(\\d+[\\w/.-]+(?:TT-BYT|NĐ-CP|QH\\d+|Lệnh|QĐ-BYT|BGDĐT|BTC|BLĐTBXH|BTTTT|BTNMT|BTP|BVHTTDL|BYT|BCT|BNN&PTNT|BKH&ĐT|BCA|BQP|BNG|BNV|CP|UBTVQH\\d+|VPCP|TTg|CT|NQ-CP|\\w+))\", ten_van_ban) # Thêm NQ-CP\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "\n",
    "    # Nếu không được, thử phân tích 'Số: ...' từ NoiDung\n",
    "    match_nd = re.search(r\"Số:\\s*([\\w/.-]+(?:TT-BYT|NĐ-CP|QH\\d+|Lệnh|QĐ-BYT|BGDĐT|BTC|BLĐTBXH|BTTTT|BTNMT|BTP|BVHTTDL|BYT|BCT|BNN&PTNT|BKH&ĐT|BCA|BQP|BNG|BNV|CP|UBTVQH\\d+|VPCP|TTg|CT|NQ-CP|\\w+))\", noi_dung, re.IGNORECASE)\n",
    "    if match_nd:\n",
    "        return match_nd.group(1)\n",
    "\n",
    "    # Nếu vẫn không được, dùng phiên bản đã làm sạch của TenVanBan\n",
    "    cleaned_name = re.sub(r\"^(Thông tư|Nghị định|Luật|Quyết định|Công văn|Lệnh|Nghị quyết)\\s+\", \"\", ten_van_ban, flags=re.IGNORECASE).strip() # Thêm Nghị quyết\n",
    "    return cleaned_name if cleaned_name else f\"UnknownID_{ten_van_ban[:20]}\"\n",
    "\n",
    "logging.info(\"Đã định nghĩa hàm parse_document_id.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98f5f4",
   "metadata": {},
   "source": [
    "## - Phân tích Ngày Hiệu lực"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf80181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,503 - INFO - Đã định nghĩa hàm parse_effective_date.\n"
     ]
    }
   ],
   "source": [
    "def parse_effective_date(date_str: str) -> str | None:\n",
    "    \"\"\"Phân tích chuỗi ngày dạng DD/MM/YYYY sang<y_bin_46>-MM-DD.\"\"\"\n",
    "    if not date_str or not isinstance(date_str, str):\n",
    "        return None\n",
    "    try:\n",
    "        # Xử lý trường hợp ngày/tháng chỉ có 1 chữ số\n",
    "        parts = date_str.split('/')\n",
    "        if len(parts) == 3:\n",
    "             day = parts[0].zfill(2)\n",
    "             month = parts[1].zfill(2)\n",
    "             year = parts[2]\n",
    "             # Thêm kiểm tra năm hợp lệ\n",
    "             current_year = datetime.now().year\n",
    "             if not year.isdigit() or int(year) < 1900 or int(year) > current_year + 10:\n",
    "                 raise ValueError(f\"Năm không hợp lệ: {year}\")\n",
    "             if not month.isdigit() or not (1 <= int(month) <= 12):\n",
    "                 raise ValueError(f\"Tháng không hợp lệ: {month}\")\n",
    "             if not day.isdigit() or not (1 <= int(day) <= 31): # Kiểm tra ngày cơ bản\n",
    "                 raise ValueError(f\"Ngày không hợp lệ: {day}\")\n",
    "             # Kiểm tra ngày tháng năm cụ thể\n",
    "             datetime.strptime(f\"{day}/{month}/{year}\", \"%d/%m/%Y\")\n",
    "             return f\"{year}-{month}-{day}\"\n",
    "        else:\n",
    "             # logging.warning(f\"Định dạng ngày không đúng DD/MM/YYYY: {date_str}\") # Log nhiều quá\n",
    "             return date_str # Trả về gốc nếu không đúng định dạng\n",
    "    except ValueError as e:\n",
    "        logging.warning(f\"Không thể phân tích ngày '{date_str}': {e}\")\n",
    "        return date_str # Trả về gốc nếu lỗi\n",
    "\n",
    "logging.info(\"Đã định nghĩa hàm parse_effective_date.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f2873",
   "metadata": {},
   "source": [
    "## Làm sạch Nội dung Văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cba581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text: str) -> tuple[str, int, int]:\n",
    "    \"\"\"Làm sạch nội dung văn bản, trả về nội dung chính và vị trí bắt đầu/kết thúc.\"\"\"\n",
    "    start_index = 0\n",
    "    end_index = len(text)\n",
    "    lines = text.splitlines()\n",
    "    if not lines: return \"\", 0, 0\n",
    "\n",
    "    # --- Tìm vị trí bắt đầu nội dung chính ---\n",
    "    found_start = False\n",
    "    start_content_markers = [\n",
    "        r\"^\\s*Chương\\s+[IVXLCDM]+\", r\"^\\s*Phần\\s+(?:thứ\\s+)?\\w+\", r\"^\\s*Điều\\s+1\\b\"\n",
    "    ]\n",
    "    title_keywords = [\"QUY ĐỊNH\", \"HƯỚNG DẪN\", \"SỬA ĐỔI\", \"BỔ SUNG\", \"BAN HÀNH\"]\n",
    "    title_line_index = -1\n",
    "    for i, line in enumerate(lines[:min(len(lines), 30)]):\n",
    "        if re.match(r\"^(BỘ|ỦY BAN|CHÍNH PHỦ|VĂN PHÒNG|CỘNG HÒA|Độc lập)\", line.strip(), re.IGNORECASE): continue\n",
    "        if any(keyword in line.upper() for keyword in title_keywords):\n",
    "            # Kiểm tra dòng trên có phải ngày tháng hoặc số hiệu không\n",
    "            if i > 0 and (re.search(r\"(?:Hà Nội|TP\\. Hồ Chí Minh|.*),\\s*ngày\\s+\\d+\\s+tháng\\s+\\d+\\s+năm\\s+\\d+\", lines[i-1]) or re.search(r\"Số:\\s*\\d+\", lines[i-1])):\n",
    "                 title_line_index = i\n",
    "                 break\n",
    "\n",
    "    citation_end_index = -1\n",
    "    search_limit = min(len(lines), 60) # Tăng giới hạn tìm căn cứ\n",
    "    start_search_citation = title_line_index + 1 if title_line_index != -1 else 0\n",
    "\n",
    "    for i in range(start_search_citation, search_limit):\n",
    "        line_strip = lines[i].strip()\n",
    "        # Tìm dòng căn cứ cuối cùng\n",
    "        if line_strip.lower().startswith(\"căn cứ\"):\n",
    "            citation_end_index = i\n",
    "        # Hoặc dòng cuối cùng kết thúc bằng ; trong khối căn cứ\n",
    "        elif line_strip.endswith(\";\") and citation_end_index >= start_search_citation:\n",
    "             citation_end_index = i\n",
    "        # Dừng nếu gặp dòng không phải căn cứ, không phải đề nghị, và không rỗng (sau khi đã thấy căn cứ)\n",
    "        elif citation_end_index != -1 and line_strip and not line_strip.lower().startswith(\"theo đề nghị\"):\n",
    "            break\n",
    "        # Dừng nếu gặp dòng \"theo đề nghị\"\n",
    "        elif line_strip.lower().startswith(\"theo đề nghị\"):\n",
    "             # Nếu dòng này nằm ngay sau căn cứ cuối cùng, coi nó là hết căn cứ\n",
    "             if i == citation_end_index + 1:\n",
    "                 citation_end_index = i\n",
    "             break # Luôn dừng khi gặp \"theo đề nghị\"\n",
    "\n",
    "    content_start_line_index = citation_end_index + 1\n",
    "    # Bỏ qua các dòng trống hoặc \"Bộ trưởng...\", \"Theo đề nghị...\" sau căn cứ\n",
    "    while content_start_line_index < len(lines):\n",
    "          line_strip = lines[content_start_line_index].strip()\n",
    "          if not line_strip: # Dòng trống\n",
    "              content_start_line_index += 1\n",
    "              continue\n",
    "          # Các chức danh/cụm từ phổ biến cần bỏ qua\n",
    "          if line_strip.lower().startswith((\"bộ trưởng\", \"thủ tướng chính phủ\", \"theo đề nghị\", \"chủ tịch\")):\n",
    "              content_start_line_index += 1\n",
    "              continue\n",
    "          # Nếu dòng hiện tại là cấu trúc hoặc có nội dung -> dừng bỏ qua\n",
    "          if any(re.match(p, line_strip, re.IGNORECASE) for p in start_content_markers) or line_strip:\n",
    "              found_start = True\n",
    "              break\n",
    "          # Nếu không phải các trường hợp trên, vẫn tiếp tục bỏ qua (có thể là tên người đề nghị)\n",
    "          content_start_line_index += 1\n",
    "\n",
    "\n",
    "    if found_start:\n",
    "        start_index = sum(len(l) + 1 for l in lines[:content_start_line_index])\n",
    "    else: # Fallback nếu không tìm thấy điểm bắt đầu rõ ràng\n",
    "        start_index = 0\n",
    "        logging.debug(f\"Không thể xác định rõ điểm bắt đầu nội dung cho VB: {text[:150]}...\")\n",
    "\n",
    "    # --- Tìm vị trí kết thúc nội dung chính ---\n",
    "    end_patterns = [\n",
    "        # Ưu tiên các marker kết thúc rõ ràng\n",
    "        r\"^\\s*PHỤ LỤC\\s*\\d*\", r\"^\\s*DANH MỤC KÈM THEO\", r\"^\\s*Biểu\\s*\\d+\", r\"^\\s*Mẫu số\\s*\\d+\",\n",
    "        r\"^\\s*Nơi nhận:\",\n",
    "        # Chữ ký (KT., Chức danh)\n",
    "        r\"^\\s*KT\\.?\\s*(?:BỘ TRƯỞNG|THỦ TƯỚNG|CHỦ TỊCH|TỔNG GIÁM ĐỐC|GIÁM ĐỐC)\",\n",
    "        r\"^\\s*(?:THỨ TRƯỞNG|PHÓ THỦ TƯỚNG|PHÓ CHỦ TỊCH|BỘ TRƯỞNG|THỦ TƯỚNG|CHỦ TỊCH|QUYỀN BỘ TRƯỞNG|CHỦ NHIỆM|TỔNG GIÁM ĐỐC|GIÁM ĐỐC)\\b\",\n",
    "        # Tên người ký (heuristic)\n",
    "        # r\"^\\s*([A-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠƯẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪỬỮỰỲÝỴỶỸĐ]+(\\s+[A-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠƯẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪỬỮỰỲÝỴỶỸĐ]+)*)$\",\n",
    "    ]\n",
    "    end_line_index = len(lines)\n",
    "    search_start_rev = max(0, len(lines) - 100)\n",
    "    if start_index > 0 :\n",
    "        start_line_approx = len(text[:start_index].splitlines())\n",
    "        search_start_rev = max(search_start_rev, start_line_approx)\n",
    "\n",
    "    found_end_marker = False\n",
    "    # Tìm từ dưới lên\n",
    "    for i in range(len(lines) - 1, search_start_rev - 1 , -1):\n",
    "         line_strip = lines[i].strip()\n",
    "         # Bỏ qua dòng quá dài hoặc quá ngắn không thể là marker\n",
    "         if len(line_strip) > 100 or len(line_strip) < 3: continue\n",
    "\n",
    "         # Kiểm tra các mẫu kết thúc\n",
    "         if any(re.match(p, line_strip, re.IGNORECASE) for p in end_patterns):\n",
    "              end_line_index = i\n",
    "              found_end_marker = True\n",
    "              # logging.debug(f\"Tìm thấy marker kết thúc '{line_strip}' tại dòng {i}\")\n",
    "              break # Dừng ngay khi thấy marker mạnh (Phụ lục, Nơi nhận, Ký thay, Chức danh)\n",
    "\n",
    "    # Nếu tìm thấy marker, lùi lên bỏ qua các dòng trống hoặc tên người ký/chức danh ngay trên đó\n",
    "    if found_end_marker:\n",
    "        temp_idx = end_line_index - 1\n",
    "        while temp_idx >= 0:\n",
    "            prev_line_strip = lines[temp_idx].strip()\n",
    "            is_empty = not prev_line_strip\n",
    "            # Chức danh thường viết hoa, ít từ\n",
    "            is_title = prev_line_strip.isupper() and len(prev_line_strip.split()) < 7\n",
    "            # Tên người ký: heuristic đơn giản (viết hoa chữ cái đầu, có khoảng trắng)\n",
    "            is_signer_name = bool(re.match(r\"^[A-ZÀ-Ỹ][a-zà-ỹ]+(?:\\s+[A-ZÀ-Ỹ][a-zà-ỹ]+)+$\", prev_line_strip))\n",
    "\n",
    "            if is_empty or is_title or is_signer_name:\n",
    "                end_line_index = temp_idx # Cập nhật dòng kết thúc thực sự\n",
    "                temp_idx -= 1\n",
    "            else:\n",
    "                # Dừng khi gặp dòng không phải là trống/chức danh/tên\n",
    "                break\n",
    "    # else: Nếu không tìm thấy marker nào, end_line_index vẫn là len(lines)\n",
    "\n",
    "    # Tính vị trí ký tự kết thúc\n",
    "    if end_line_index < len(lines):\n",
    "        end_index = sum(len(l) + 1 for l in lines[:end_line_index])\n",
    "        end_index = max(0, end_index -1) if end_index > 0 else 0 # Trừ newline cuối\n",
    "    else:\n",
    "        end_index = len(text)\n",
    "\n",
    "    # Đảm bảo end >= start và nội dung không quá ngắn\n",
    "    end_index = max(start_index, end_index)\n",
    "    main_content = text[start_index:end_index].strip()\n",
    "    if len(main_content) < 50: # Nếu nội dung chính quá ngắn sau khi cắt -> có thể lỗi -> trả về gần như toàn bộ\n",
    "         logging.warning(f\"Nội dung chính quá ngắn ({len(main_content)} chars) sau khi làm sạch. Kiểm tra lại VB: {text[:150]}...\")\n",
    "         # Có thể chọn không cắt nếu quá ngắn: return text.strip(), 0, len(text)\n",
    "         pass # Hiện tại vẫn giữ nội dung đã cắt\n",
    "\n",
    "    # Xóa các dòng chỉ chứa số trang ở cuối/đầu nếu có\n",
    "    main_content = re.sub(r'\\n\\s*\\d+\\s*$', '', main_content).strip()\n",
    "    main_content = re.sub(r'^\\s*\\d+\\s*\\n', '', main_content).strip()\n",
    "\n",
    "    return main_content, start_index, end_index\n",
    "\n",
    "# logging.info(\"Đã định nghĩa hàm clean_content (cải thiện).\") # Bỏ bớt log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ef942",
   "metadata": {},
   "source": [
    "## Tìm Yếu tố Cấu trúc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a389d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,560 - INFO - Đã định nghĩa hàm find_structural_elements.\n"
     ]
    }
   ],
   "source": [
    "def find_structural_elements(text: str) -> list:\n",
    "    \"\"\"Tìm tất cả các yếu tố cấu trúc (Chương, Mục, Điều, Khoản, Điểm) và vị trí của chúng.\"\"\"\n",
    "    elements = []\n",
    "    # Pattern được tối ưu hơn để bắt tiêu đề chính xác hơn\n",
    "    patterns = {\n",
    "        # Chương/Mục/Điều: Bắt số hiệu (la mã/thường), dấu chấm tùy chọn, sau đó là tiêu đề (không tham lam) đến hết dòng hoặc đến cấu trúc tiếp theo\n",
    "        'Chương': r\"^\\s*Chương\\s+([IVXLCDM\\d]+)\\b\\.?\\s*(.*?)(?=\\n\\s*(?:Chương|Mục|Điều|\\d+\\.|[a-zđ]\\))|$)\",\n",
    "        'Mục': r\"^\\s*Mục\\s+(\\d+|[IVXLCDM]+)\\b\\.?\\s*(.*?)(?=\\n\\s*(?:Chương|Mục|Điều|\\d+\\.|[a-zđ]\\))|$)\",\n",
    "        'Điều': r\"^\\s*Điều\\s+(\\d+)\\b\\.?\\s*(.*?)(?=\\n\\s*(?:Chương|Mục|Điều|\\d+\\.|[a-zđ]\\))|$)\",\n",
    "        'Khoản': r\"^\\s*(\\d+)\\.\\s+\",\n",
    "        'Điểm': r\"^\\s*([a-zđ])\\)\\s+\",\n",
    "    }\n",
    "\n",
    "    for type, pattern in patterns.items():\n",
    "        for match in re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE):\n",
    "            identifier = match.group(1).strip()\n",
    "            # Lấy tiêu đề nếu có group 2\n",
    "            title = match.group(2).strip().replace('\\n', ' ') if len(match.groups()) > 1 else \"\"\n",
    "            # Chỉ lấy title nếu nó không bắt đầu bằng cấu trúc khác và không quá dài\n",
    "            if title and len(title) < 250: # Tăng giới hạn độ dài title\n",
    "                 pass\n",
    "            else:\n",
    "                 title = \"\"\n",
    "\n",
    "            elements.append({\n",
    "                'type': type,\n",
    "                'identifier': identifier,\n",
    "                'title': title,\n",
    "                'start': match.start(),\n",
    "                'end': match.end()\n",
    "            })\n",
    "\n",
    "    elements.sort(key=lambda x: x['start'])\n",
    "    return elements\n",
    "logging.info(\"Đã định nghĩa hàm find_structural_elements.\") # Bỏ bớt log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c956f9af",
   "metadata": {},
   "source": [
    "## Xác định Ngữ cảnh Cấu trúc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d078c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,584 - INFO - Đã định nghĩa hàm get_contextual_structure.\n"
     ]
    }
   ],
   "source": [
    "def get_contextual_structure(char_index: int, sorted_elements: list) -> dict:\n",
    "    \"\"\"Tìm ngữ cảnh cấu trúc (Chương->Mục->Điều->Khoản->Điểm) cho một vị trí ký tự cụ thể.\"\"\"\n",
    "    context = {}\n",
    "    last_element_of_type = {}\n",
    "    hierarchy = ['Chương', 'Mục', 'Điều', 'Khoản', 'Điểm']\n",
    "\n",
    "    current_context = {}\n",
    "    for element in sorted_elements:\n",
    "        if element['start'] <= char_index:\n",
    "            current_context[element['type']] = {\n",
    "                'identifier': element['identifier'],\n",
    "                'title': element.get('title', '')\n",
    "            }\n",
    "            current_level_index = hierarchy.index(element['type'])\n",
    "            # Xóa ngữ cảnh cấp thấp hơn khi gặp cấp cao hơn\n",
    "            to_delete = []\n",
    "            for existing_type in current_context:\n",
    "                if existing_type != element['type'] and hierarchy.index(existing_type) > current_level_index:\n",
    "                     to_delete.append(existing_type)\n",
    "            for key_to_del in to_delete:\n",
    "                 del current_context[key_to_del]\n",
    "\n",
    "            last_element_of_type = current_context.copy()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    location_parts = []\n",
    "    context_dict = {}\n",
    "    for struct_type in hierarchy:\n",
    "         if struct_type in last_element_of_type:\n",
    "             info = last_element_of_type[struct_type]\n",
    "             part = f\"{struct_type} {info['identifier']}\"\n",
    "             # Chỉ thêm title cho Chương, Mục, Điều\n",
    "             if struct_type in ['Chương', 'Mục', 'Điều'] and info['title'] and len(info['title']) < 150:\n",
    "                 part += f\": {info['title'][:100]}...\" # Rút gọn title nếu quá dài\n",
    "             location_parts.append(part)\n",
    "             context_dict[struct_type] = info['identifier']\n",
    "\n",
    "    context_dict['location_detail'] = \" -> \".join(location_parts) if location_parts else \"Không có cấu trúc\"\n",
    "    return context_dict\n",
    "\n",
    "logging.info(\"Đã định nghĩa hàm get_contextual_structure.\") # Bỏ bớt log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c750b",
   "metadata": {},
   "source": [
    "## Tiền xử lý Text trước Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9113409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,607 - INFO - Đã định nghĩa hàm preprocess_text_for_embedding (cải thiện xử lý dấu chấm và gạch nối).\n"
     ]
    }
   ],
   "source": [
    "import re # Đảm bảo re đã được import\n",
    "import unicodedata # Thêm import để chuẩn hóa Unicode nếu cần\n",
    "\n",
    "def preprocess_text_for_embedding(text: str) -> str:\n",
    "    \"\"\"Sửa các lỗi định dạng phổ biến trong text trước khi embedding.\"\"\"\n",
    "    if not text: return \"\"\n",
    "\n",
    "    # ===> CẢI TIẾN XỬ LÝ DẤU CHẤM <====\n",
    "    # 1. Xử lý chuỗi dấu chấm ASCII liền nhau (3+)\n",
    "    text = re.sub(r'\\.{3,}', ' ', text)\n",
    "    # 2. Xử lý ký tự dấu ba chấm Unicode (…) liền nhau (1+)\n",
    "    text = re.sub(r'…+', ' ', text)\n",
    "    # 3. (MỚI) Xử lý chuỗi dấu chấm ASCII có thể có khoảng trắng xen kẽ (3+ dấu chấm)\n",
    "    #    Ví dụ: '. . .', '.    .    .', ' . . . '\n",
    "    #    Pattern này tìm (dấu chấm theo sau bởi 0 hoặc nhiều khoảng trắng) lặp lại 3 lần trở lên\n",
    "    text = re.sub(r'(\\.\\s*){3,}', ' ', text)\n",
    "\n",
    "    # Thay thế chuỗi dài dấu gạch nối bằng khoảng trắng\n",
    "    text = re.sub(r'-{3,}', ' ', text)\n",
    "\n",
    "    # Sửa lỗi dính chữ cụ thể (ví dụ)\n",
    "    text = text.replace(\"hoặcc)\", \"hoặc c)\")\n",
    "    text = text.replace(\"thi hành1.\", \"thi hành 1.\")\n",
    "    text = text.replace(\"năm 2025.2.\", \"năm 2025. 2.\")\n",
    "    # Thêm các trường hợp khác nếu cần dựa trên lỗi thực tế\n",
    "\n",
    "    # Thêm khoảng trắng sau dấu câu nếu thiếu (heuristic)\n",
    "    text = re.sub(r'([.;,:?)])([a-zA-Z0-9À-ỹ])', r'\\1 \\2', text)\n",
    "\n",
    "    # Thêm khoảng trắng trước số/chữ cái đầu mục nếu dính liền chữ (heuristic)\n",
    "    text = re.sub(r'([a-zA-ZÀ-ỹ])(\\d+\\.|[a-zđ]\\))', r'\\1 \\2', text)\n",
    "\n",
    "    # Chuẩn hóa khoảng trắng (thay thế nhiều khoảng trắng bằng 1, xóa khoảng trắng đầu/cuối)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # (Tùy chọn) Chuẩn hóa Unicode về dạng NFKC (thường hữu ích)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "    # (Tùy chọn) Loại bỏ ký tự lạ (Whitelist - cần kiểm tra kỹ)\n",
    "    allowed_chars = r'\\w\\s\\d.,;:?!%()-/+ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂưạảấầẩẫậắằẳẵặẹẻẽềềểỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲÝỴỶỸửữựỳýỵỷỹ'\n",
    "    text = re.sub(f'[^{allowed_chars}]', ' ', text, flags=re.UNICODE) # Thay ký tự lạ bằng cách\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Dọn dẹp khoảng trắng lại\n",
    "\n",
    "    return text\n",
    "\n",
    "logging.info(\"Đã định nghĩa hàm preprocess_text_for_embedding (cải thiện xử lý dấu chấm và gạch nối).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769fd8f8",
   "metadata": {},
   "source": [
    "## Khởi tạo Model Embedding, Kho Vector (Kiểm tra FAISS) và Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2112576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:15,635 - INFO - --- Khởi tạo Model Embedding ---\n",
      "2025-04-21 03:00:30,237 - WARNING - From c:\\Users\\phamd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2025-04-21 03:00:30,640 - INFO - PyTorch version 2.6.0.dev20241206+cu126 available.\n",
      "2025-04-21 03:00:30,644 - INFO - TensorFlow version 2.18.0 available.\n",
      "2025-04-21 03:00:31,269 - INFO - Load pretrained SentenceTransformer: bkai-foundation-models/vietnamese-bi-encoder\n",
      "2025-04-21 03:00:36,617 - INFO - Model Embedding 'bkai-foundation-models/vietnamese-bi-encoder' đã sẵn sàng.\n",
      "2025-04-21 03:00:36,617 - INFO - Đã khởi tạo Text Splitter với chunk_size=1000, chunk_overlap=150\n",
      "2025-04-21 03:00:36,621 - INFO - Chưa có index FAISS tại: db_faiss_phapluat_yte_full_final. Index sẽ được tạo mới.\n",
      "2025-04-21 03:00:36,621 - INFO - Embedding đã sẵn sàng.\n",
      "2025-04-21 03:00:36,623 - INFO - Vector store FAISS sẽ được tạo mới.\n"
     ]
    }
   ],
   "source": [
    "# --- Khởi tạo các thành phần dùng chung ---\n",
    "logging.info(\"--- Khởi tạo Model Embedding ---\")\n",
    "embeddings = None\n",
    "if 'HuggingFaceEmbeddings' in globals() and HuggingFaceEmbeddings:\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME,\n",
    "                                         model_kwargs={'device': 'cpu'})\n",
    "        logging.info(f\"Model Embedding '{MODEL_NAME}' đã sẵn sàng.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi khởi tạo model embedding: {e}\", exc_info=True)\n",
    "else:\n",
    "     logging.error(\"Thư viện HuggingFaceEmbeddings chưa được import/khởi tạo thành công.\")\n",
    "\n",
    "# Khởi tạo Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    add_start_index=True,\n",
    "    separators=SEPARATORS\n",
    ")\n",
    "logging.info(f\"Đã khởi tạo Text Splitter với chunk_size={CHUNK_SIZE}, chunk_overlap={CHUNK_OVERLAP}\")\n",
    "\n",
    "# --- Khởi tạo biến vectordb là None ban đầu ---\n",
    "vectordb = None\n",
    "faiss_index_exists = False\n",
    "if FAISS:\n",
    "    faiss_file = Path(faiss_index_path).joinpath(\"index.faiss\")\n",
    "    pkl_file = Path(faiss_index_path).joinpath(\"index.pkl\")\n",
    "    if faiss_file.exists() and pkl_file.exists():\n",
    "         faiss_index_exists = True\n",
    "         logging.info(f\"Phát hiện index FAISS đã tồn tại tại: {faiss_index_path}\")\n",
    "         if LOAD_EXISTING_FAISS_INDEX and embeddings:\n",
    "             logging.info(\"Đang thử tải index FAISS hiện có...\")\n",
    "             try:\n",
    "                 vectordb = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "                 logging.info(f\"Đã tải index FAISS thành công. Số lượng vector hiện tại: {vectordb.index.ntotal}\")\n",
    "             except EOFError as eof:\n",
    "                  logging.error(f\"Lỗi EOFError khi tải index FAISS: {eof}. Sẽ tạo index mới.\", exc_info=True)\n",
    "                  vectordb = None ; faiss_index_exists = False\n",
    "                  try: faiss_file.unlink(missing_ok=True); pkl_file.unlink(missing_ok=True); logging.info(\"Đã xóa file index FAISS bị lỗi.\")\n",
    "                  except OSError as del_err: logging.error(f\"Không thể xóa file index FAISS bị lỗi: {del_err}\")\n",
    "             except Exception as e:\n",
    "                 logging.error(f\"Lỗi khác khi tải index FAISS: {e}. Sẽ tạo index mới nếu cần.\", exc_info=True)\n",
    "                 vectordb = None ; faiss_index_exists = False\n",
    "         elif not LOAD_EXISTING_FAISS_INDEX:\n",
    "             logging.info(\"Cấu hình không tải index cũ. Index sẽ được tạo mới và ghi đè.\")\n",
    "             faiss_index_exists = False # Đặt là false để ghi đè ở bước sau\n",
    "             # Xóa file cũ nếu muốn ghi đè hoàn toàn\n",
    "             try: faiss_file.unlink(missing_ok=True); pkl_file.unlink(missing_ok=True); logging.info(\"Đã xóa file index FAISS cũ để ghi đè.\")\n",
    "             except OSError as del_err: logging.error(f\"Không thể xóa file index FAISS cũ để ghi đè: {del_err}\")\n",
    "\n",
    "         elif not embeddings:\n",
    "              logging.warning(\"Model embedding chưa sẵn sàng, không thể tải index FAISS.\")\n",
    "    else:\n",
    "         logging.info(f\"Chưa có index FAISS tại: {faiss_index_path}. Index sẽ được tạo mới.\")\n",
    "else:\n",
    "    logging.error(\"Thư viện FAISS chưa được import thành công.\")\n",
    "\n",
    "if not embeddings: logging.error(\"Không thể khởi tạo Embedding. Dừng xử lý.\")\n",
    "else: logging.info(\"Embedding đã sẵn sàng.\")\n",
    "if vectordb: logging.info(\"Vector store FAISS đã được tải.\")\n",
    "elif faiss_index_exists and not LOAD_EXISTING_FAISS_INDEX: logging.info(\"Vector store FAISS sẽ được tạo mới (ghi đè index cũ).\")\n",
    "elif not faiss_index_exists: logging.info(\"Vector store FAISS sẽ được tạo mới.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ff6ad",
   "metadata": {},
   "source": [
    "## Tải Dữ liệu từ File JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac6955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:36,664 - INFO - --- Bắt đầu tải dữ liệu từ data_vbpl_boyte_full_details.json ---\n",
      "2025-04-21 03:00:36,826 - INFO - Đã tải thành công 614 văn bản từ data_vbpl_boyte_full_details.json\n",
      "2025-04-21 03:00:36,827 - INFO - Tổng số văn bản sẽ được xử lý: 614\n"
     ]
    }
   ],
   "source": [
    "# --- Tải Dữ liệu từ File JSON ---\n",
    "all_documents_data = [] # Khởi tạo rỗng\n",
    "if JSON_FILE_PATH.exists():\n",
    "    logging.info(f\"--- Bắt đầu tải dữ liệu từ {JSON_FILE_PATH} ---\")\n",
    "    all_documents_data = load_json_data(JSON_FILE_PATH) # Gọi hàm load_json_data\n",
    "    if not all_documents_data:\n",
    "        logging.warning(\"Không tải được dữ liệu hoặc file rỗng. Kiểm tra lại file JSON và đường dẫn.\")\n",
    "    else:\n",
    "        logging.info(f\"Tổng số văn bản sẽ được xử lý: {len(all_documents_data)}\")\n",
    "else:\n",
    "    logging.error(f\"File dữ liệu không tồn tại: {JSON_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c115ee",
   "metadata": {},
   "source": [
    "##  Xử lý và Gom Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdbe7f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:36,858 - INFO - --- Bắt đầu xử lý 614 văn bản để tạo chunks ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c4ced7e1414139a74bf10ea3e06c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Đang xử lý văn bản:   0%|          | 0/614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:39,175 - WARNING - Nội dung chính quá ngắn (9 chars) sau khi làm sạch. Kiểm tra lại VB: Toàn quốc...\n",
      "2025-04-21 03:00:44,546 - INFO - --- Vòng lặp xử lý hoàn tất ---\n",
      "2025-04-21 03:00:44,549 - INFO - Số văn bản đã xử lý thành công (để tạo chunk): 612\n",
      "2025-04-21 03:00:44,550 - INFO - Số văn bản bị bỏ qua/lỗi: 2\n",
      "2025-04-21 03:00:44,551 - INFO - Tổng số đoạn (chunks) đã chuẩn bị: 15498\n"
     ]
    }
   ],
   "source": [
    "# --- Vòng lặp Xử lý Chính ---\n",
    "processed_doc_count = 0\n",
    "error_doc_count = 0\n",
    "total_chunks_prepared = 0\n",
    "all_processed_chunks = [] # Gom tất cả các chunks hợp lệ ở đây\n",
    "\n",
    "# Chỉ chạy nếu đã tải được dữ liệu và khởi tạo embeddings/FAISS thành công\n",
    "if all_documents_data and embeddings and FAISS:\n",
    "    logging.info(f\"--- Bắt đầu xử lý {len(all_documents_data)} văn bản để tạo chunks ---\")\n",
    "    for doc_data in tqdm(all_documents_data, desc=\"Đang xử lý văn bản\"):\n",
    "        doc_id = \"Unknown\"\n",
    "        try:\n",
    "            # --- Trích xuất Thông tin Cơ bản & Metadata ---\n",
    "            ten_van_ban = doc_data.get(\"TenVanBan\", \"\")\n",
    "            noi_dung = doc_data.get(\"NoiDung\", \"\")\n",
    "            if not noi_dung:\n",
    "                logging.debug(f\"Văn bản '{ten_van_ban}' không có nội dung. Bỏ qua.\")\n",
    "                error_doc_count += 1\n",
    "                continue\n",
    "\n",
    "            doc_id = parse_document_id(ten_van_ban, noi_dung)\n",
    "            parsed_date = parse_effective_date(doc_data.get(\"NgayHieuLuc\"))\n",
    "\n",
    "            base_metadata = {\n",
    "                \"document_id\": doc_id,\n",
    "                \"document_type\": doc_data.get(\"LoaiVanBan_ThuocTinh\", \"UnknownType\"),\n",
    "                \"effective_date\": parsed_date if parsed_date else doc_data.get(\"NgayHieuLuc\", \"N/A\"),\n",
    "                \"source_link\": doc_data.get(\"DuongLink\", \"N/A\"),\n",
    "                \"domain\": doc_data.get(\"LinhVuc\", \"N/A\")\n",
    "            }\n",
    "\n",
    "            # --- Làm sạch Nội dung ---\n",
    "            main_content, content_start_offset, content_end_offset = clean_content(noi_dung)\n",
    "            if not main_content:\n",
    "                logging.debug(f\"Không thể trích xuất nội dung chính cho {doc_id}. Bỏ qua.\")\n",
    "                error_doc_count += 1\n",
    "                continue\n",
    "\n",
    "            # --- Tìm các Yếu tố Cấu trúc trong Nội dung chính ---\n",
    "            structural_elements = find_structural_elements(main_content)\n",
    "\n",
    "            # --- Phân chia thành các Đoạn (Chunks) ---\n",
    "            temp_docs = text_splitter.create_documents([main_content], metadatas=[base_metadata])\n",
    "\n",
    "            doc_chunk_count = 0\n",
    "            # --- Gán Metadata Cấu trúc và Tiền xử lý Nội dung Chunk ---\n",
    "            for temp_doc in temp_docs:\n",
    "                chunk_start_in_main = temp_doc.metadata.get(\"start_index\", 0)\n",
    "                structure_context = get_contextual_structure(chunk_start_in_main, structural_elements)\n",
    "                final_metadata = base_metadata.copy()\n",
    "                final_metadata.update(structure_context)\n",
    "                final_metadata[\"start_index_in_main\"] = chunk_start_in_main\n",
    "                if \"start_index\" in final_metadata: del final_metadata[\"start_index\"]\n",
    "\n",
    "                # ====> ÁP DỤNG TIỀN XỬ LÝ CHO NỘI DUNG CHUNK <====\n",
    "                raw_page_content = str(temp_doc.page_content)\n",
    "                preprocessed_content = preprocess_text_for_embedding(raw_page_content)\n",
    "\n",
    "                if preprocessed_content:\n",
    "                    final_chunk_doc = Document(page_content=preprocessed_content, metadata=final_metadata)\n",
    "                    all_processed_chunks.append(final_chunk_doc)\n",
    "                    doc_chunk_count += 1\n",
    "                else:\n",
    "                    logging.debug(f\"Bỏ qua chunk rỗng sau tiền xử lý cho {doc_id}\")\n",
    "\n",
    "            if doc_chunk_count > 0:\n",
    "                 processed_doc_count += 1\n",
    "                 total_chunks_prepared += doc_chunk_count\n",
    "            else:\n",
    "                 # Chỉ log warning nếu văn bản ban đầu có nội dung đáng kể\n",
    "                 if len(main_content) > 50:\n",
    "                      logging.warning(f\"Không tạo được chunk hợp lệ nào cho {doc_id} (dù đã có main_content).\")\n",
    "                 error_doc_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            error_doc_count += 1\n",
    "            logging.error(f\"Lỗi không xác định khi xử lý văn bản (ID: {doc_id}): {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "    logging.info(\"--- Vòng lặp xử lý hoàn tất ---\")\n",
    "    logging.info(f\"Số văn bản đã xử lý thành công (để tạo chunk): {processed_doc_count}\")\n",
    "    logging.info(f\"Số văn bản bị bỏ qua/lỗi: {error_doc_count}\")\n",
    "    logging.info(f\"Tổng số đoạn (chunks) đã chuẩn bị: {total_chunks_prepared}\")\n",
    "\n",
    "elif not all_documents_data:\n",
    "    logging.error(\"Dữ liệu văn bản rỗng hoặc không được tải. Không thể xử lý.\")\n",
    "else:\n",
    "    logging.error(\"Embedding hoặc thư viện FAISS chưa được khởi tạo/import thành công. Không thể xử lý.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750268f",
   "metadata": {},
   "source": [
    "## Kiểm tra và Báo cáo Chunk lỗi Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d6b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:00:44,603 - INFO - --- Bắt đầu kiểm tra embedding cho 15498 chunks đã chuẩn bị ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc706b58fcb547a88c0c5224d8678d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Kiểm tra embedding sau tiền xử lý:   0%|          | 0/15498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:47:51,379 - INFO - --- Kiểm tra embedding tất cả các chunk sau tiền xử lý thành công ---\n"
     ]
    }
   ],
   "source": [
    "# --- KIỂM TRA LẠI EMBEDDING TỪNG CHUNK (SAU TIỀN XỬ LÝ) ---\n",
    "logging.info(f\"--- Bắt đầu kiểm tra embedding cho {len(all_processed_chunks)} chunks đã chuẩn bị ---\")\n",
    "problematic_chunks_indices_after_pp = []\n",
    "good_chunks_count = 0\n",
    "good_chunks_temp_list = [] # Tạm lưu chunk tốt nếu cần lọc\n",
    "\n",
    "# Chỉ chạy nếu có chunks và embeddings\n",
    "if all_processed_chunks and embeddings:\n",
    "    for i, chunk_doc in enumerate(tqdm(all_processed_chunks, desc=\"Kiểm tra embedding sau tiền xử lý\")):\n",
    "        try:\n",
    "            page_content_str = str(chunk_doc.page_content)\n",
    "            if not page_content_str.strip():\n",
    "                 # logging.warning(f\"Chunk #{i} rỗng sau tiền xử lý, bỏ qua.\") # Giảm log\n",
    "                 continue\n",
    "            # Thử embed nội dung chunk đã tiền xử lý\n",
    "            _ = embeddings.embed_documents([page_content_str])\n",
    "            good_chunks_count += 1\n",
    "            good_chunks_temp_list.append(chunk_doc) # Thêm vào list tạm thời\n",
    "        except IndexError as e:\n",
    "            logging.error(f\"Lỗi IndexError khi embed chunk #{i} (SAU TIỀN XỬ LÝ)\")\n",
    "            doc_id_err = chunk_doc.metadata.get('document_id', 'N/A')\n",
    "            loc_err = chunk_doc.metadata.get('location_detail', 'N/A')\n",
    "            logging.error(f\"  Văn bản: {doc_id_err}\")\n",
    "            logging.error(f\"  Vị trí: {loc_err}\")\n",
    "            content_preview_err = page_content_str[:150]\n",
    "            logging.error(f\"  Nội dung đã tiền xử lý (bắt đầu): '{content_preview_err}...'\")\n",
    "            logging.error(f\"  Lỗi chi tiết: {e}\")\n",
    "            problematic_chunks_indices_after_pp.append(i)\n",
    "        except Exception as e_other:\n",
    "             logging.error(f\"Lỗi khác khi embed chunk #{i} (VB: {chunk_doc.metadata.get('document_id', 'N/A')}): {e_other}\", exc_info=True)\n",
    "             problematic_chunks_indices_after_pp.append(i)\n",
    "\n",
    "    if problematic_chunks_indices_after_pp:\n",
    "        logging.warning(f\"Tìm thấy {len(problematic_chunks_indices_after_pp)} chunks VẪN gây lỗi embedding sau tiền xử lý tại các vị trí (index): {problematic_chunks_indices_after_pp}\")\n",
    "        logging.info(f\"Số chunks embed thành công ước tính: {good_chunks_count}\")\n",
    "        # ====> TÙY CHỌN: Lọc bỏ chunk lỗi để chạy tiếp Ô 12 <====\n",
    "        # Bỏ comment dòng dưới nếu muốn lọc bỏ chunk lỗi và chỉ xử lý chunk tốt\n",
    "        all_processed_chunks = good_chunks_temp_list\n",
    "        logging.info(f\"Đã cập nhật 'all_processed_chunks' chỉ chứa {len(all_processed_chunks)} chunks hợp lệ cuối cùng.\")\n",
    "    else:\n",
    "        logging.info(\"--- Kiểm tra embedding tất cả các chunk sau tiền xử lý thành công ---\")\n",
    "else:\n",
    "    logging.warning(\"Không có chunks để kiểm tra embedding hoặc embedding model chưa sẵn sàng.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8568e45",
   "metadata": {},
   "source": [
    "## Tạo hoặc Cập nhật Index FAISS & Lưu trữ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905b77f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:47:51,433 - INFO - --- Bắt đầu tạo hoặc cập nhật index FAISS từ 15498 chunks đã chuẩn bị ---\n",
      "2025-04-21 03:47:51,438 - INFO - Đang tạo index FAISS mới từ đầu...\n",
      "2025-04-21 04:23:43,657 - INFO - Loading faiss with AVX2 support.\n",
      "2025-04-21 04:23:43,682 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2025-04-21 04:23:43,698 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.\n",
      "2025-04-21 04:23:44,897 - INFO - Tạo index FAISS mới thành công với 15498 vectors.\n",
      "2025-04-21 04:23:44,899 - INFO - --- Lưu trữ index FAISS vào thư mục 'db_faiss_phapluat_yte_full_final' ---\n",
      "2025-04-21 04:23:45,053 - INFO - Lưu trữ FAISS thành công sau 0.15 giây.\n",
      "2025-04-21 04:23:45,053 - INFO - Hoàn tất quá trình tạo/cập nhật/lưu index FAISS sau 2153.62 giây.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if 'all_processed_chunks' in locals() and all_processed_chunks and embeddings and FAISS:\n",
    "    logging.info(f\"--- Bắt đầu tạo hoặc cập nhật index FAISS từ {len(all_processed_chunks)} chunks đã chuẩn bị ---\")\n",
    "    start_index_time = time.time()\n",
    "    save_needed = False\n",
    "    try:\n",
    "        if vectordb and faiss_index_exists and LOAD_EXISTING_FAISS_INDEX:\n",
    "             logging.info(f\"Đang thêm {len(all_processed_chunks)} chunks mới vào index FAISS hiện có (Tổng cũ: {vectordb.index.ntotal})...\")\n",
    "             if all_processed_chunks:\n",
    "                 vectordb.add_documents(documents=all_processed_chunks)\n",
    "                 logging.info(f\"Thêm chunks mới thành công. Tổng số vector mới: {vectordb.index.ntotal}\")\n",
    "                 save_needed = True\n",
    "             else:\n",
    "                  logging.info(\"Không có chunks mới để thêm vào index hiện có.\")\n",
    "        else:\n",
    "             logging.info(\"Đang tạo index FAISS mới từ đầu...\")\n",
    "             if all_processed_chunks:\n",
    "                 vectordb = FAISS.from_documents(documents=all_processed_chunks, embedding=embeddings)\n",
    "                 logging.info(f\"Tạo index FAISS mới thành công với {vectordb.index.ntotal} vectors.\")\n",
    "                 save_needed = True\n",
    "             else:\n",
    "                  logging.warning(\"Không có chunks hợp lệ để tạo index FAISS mới.\")\n",
    "                  vectordb = None\n",
    "\n",
    "        if vectordb and save_needed:\n",
    "            logging.info(f\"--- Lưu trữ index FAISS vào thư mục '{faiss_index_path}' ---\")\n",
    "            start_save = time.time()\n",
    "            vectordb.save_local(folder_path=faiss_index_path)\n",
    "            end_save = time.time()\n",
    "            logging.info(f\"Lưu trữ FAISS thành công sau {end_save - start_save:.2f} giây.\")\n",
    "        elif not save_needed:\n",
    "             logging.info(\"Không có thay đổi hoặc không tạo mới index, không cần lưu trữ.\")\n",
    "        else: \n",
    "             logging.error(\"Không thể tạo hoặc cập nhật đối tượng vectordb FAISS. Không lưu trữ.\")\n",
    "\n",
    "    except IndexError as idx_err:\n",
    "         logging.error(f\"Lỗi IndexError khi tạo/thêm vào FAISS (vẫn còn chunk lỗi?): {idx_err}\", exc_info=True)\n",
    "         logging.error(\"Gợi ý: Chạy lại ô kiểm tra embedding (11.5) để xem chi tiết chunk lỗi HOẶC cải thiện hàm preprocess_text_for_embedding (Ô 8.5) HOẶC thử model embedding khác (Ô 2). Xem xét bỏ comment dòng lọc chunk ở Ô 11.5 để chạy tiếp.\")\n",
    "         vectordb = None \n",
    "    except Exception as faiss_err:\n",
    "         logging.error(f\"Lỗi khác khi tạo/cập nhật/lưu index FAISS: {faiss_err}\", exc_info=True)\n",
    "         vectordb = None \n",
    "\n",
    "    end_index_time = time.time()\n",
    "    logging.info(f\"Hoàn tất quá trình tạo/cập nhật/lưu index FAISS sau {end_index_time - start_index_time:.2f} giây.\")\n",
    "\n",
    "elif not ('all_processed_chunks' in locals() and all_processed_chunks) and ('processed_doc_count' in locals() and processed_doc_count > 0):\n",
    "     logging.warning(\"Đã xử lý văn bản nhưng không có chunks hợp lệ nào được chuẩn bị sau khi lọc lỗi embedding (nếu có). Không tạo/lưu index.\")\n",
    "elif not ('embeddings' in locals() and embeddings):\n",
    "     logging.error(\"Model embedding không sẵn sàng. Không thể tạo index.\")\n",
    "elif not ('FAISS' in globals() and FAISS):\n",
    "     logging.error(\"Thư viện FAISS không sẵn sàng. Không thể tạo index.\")\n",
    "else:\n",
    "    logging.info(\"Không có chunks nào được xử lý hoặc không có dữ liệu đầu vào. Không tạo/lưu index FAISS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ad94f",
   "metadata": {},
   "source": [
    "# --- Kiểm tra Cuối cùng ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf991c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 04:23:45,086 - INFO - --- Kiểm tra cuối cùng ---\n",
      "2025-04-21 04:23:45,089 - INFO - Đang tải lại index FAISS từ 'db_faiss_phapluat_yte_full_final' để kiểm tra...\n",
      "2025-04-21 04:23:45,265 - INFO - Index FAISS tải thành công. Tổng số đoạn (chunks/vectors): 15498\n",
      "2025-04-21 04:23:45,265 - INFO - Thực hiện truy vấn thử nghiệm...\n",
      "2025-04-21 04:23:45,322 - INFO - Truy vấn hoàn tất sau 0.057 giây.\n",
      "2025-04-21 04:23:45,323 - INFO - Truy vấn thử 'Điều kiện cấp giấy chứng nhận thực phẩm xuất khẩu' tìm thấy 5 kết quả (top 5):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Kết quả 1 ---\n",
      "Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '3', 'Khoản': '2', 'Điểm': 'đ', 'location_detail': 'Điều 3: Giấy chứng nhận đối với thực phẩm xuất khẩu... -> Khoản 2 -> Điểm đ', 'start_index_in_main': 1523}\n",
      "Nội dung (300 ký tự đầu): Số và thời hạn hiệu lực của giấy chứng nhận cơ sở đủ điều kiện an toàn thực phẩm hoặc tương đương đối với giấy chứng nhận liên quan đến cơ sở sản xuất thực phẩm; e) Tên và địa chỉ của tổ chức, cá nhân xuất khẩu; cơ sở sản xuất; g) Căn cứ trên phiếu kiểm nghiệm của lô sản phẩm thực phẩm xuất khẩu, xá...\n",
      "\n",
      "--- Kết quả 2 ---\n",
      "Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '4', 'location_detail': 'Điều 4: Hồ sơ đề nghị cấp giấy chứng nhận...', 'start_index_in_main': 2378}\n",
      "Nội dung (300 ký tự đầu): Điều 4. Hồ sơ đề nghị cấp giấy chứng nhận Hồ sơ đề nghị cấp giấy chứng nhận cho 01 (mộ t) lô hàng xuất khẩu hoặc một cơ sở sản xuất thực phẩm xuất khẩu gồm: 1. Đơn đề nghị cấp giấy chứng nhận theo mẫu quy định tại Phụ lục ban hành kèm theo Thông tư này; 2. Giấy chứng nhận cơ sở đủ điều kiện an toàn ...\n",
      "\n",
      "--- Kết quả 3 ---\n",
      "Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '3', 'location_detail': 'Điều 3: Giấy chứng nhận đối với thực phẩm xuất khẩu...', 'start_index_in_main': 613}\n",
      "Nội dung (300 ký tự đầu): Điều 3. Giấy chứng nhận đối với thực phẩm xuất khẩu 1. Giấy chứng nhận (Giấy chứng nhận y tế hoặc Giấy chứng nhận khác có liên quan trong trường hợp có yêu cầu của nước nhập khẩ u) được cấp cho sản phẩm thực phẩm, phụ gia thực phẩm, chất hỗ trợ chế biến; dụng cụ, vật liệu bao gói, chứa đựng thực phẩ...\n",
      "\n",
      "--- Kết quả 4 ---\n",
      "Metadata: {'document_id': '26/2012/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2012-01-15', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=28010&Keyword=', 'domain': 'Vệ sinh an toàn và dinh dưỡng', 'Chương': 'II', 'Điều': '5', 'Khoản': '3', 'location_detail': 'Chương II: HỒ SƠ, THỦ TỤC VÀ THẨM QUYỀN CẤP GIẤY CHỨNG NHẬN CƠ SỞ ĐỦ ĐIỀU KIỆN AN TOÀN THỰC PHẨM... -> Điều 5: Thủ tục cấp Giấy chứng nhận... -> Khoản 3', 'start_index_in_main': 5395}\n",
      "Nội dung (300 ký tự đầu): 3. Cấp Giấy chứng nhận: a) Trường hợp cơ sở đủ điều kiện an toàn thực phẩm theo quy định, cơ quan tiếp nhận hồ sơ cấp Giấy chứng nhận theo mẫu ban hành kèm theo Thông tư này. Đối với cơ sở sản xuất, kinh doanh thực phẩm theo mùa vụ phải ghi rõ thời gian hoạt động trong Giấy chứng nhận; d) Trường hợp...\n",
      "\n",
      "--- Kết quả 5 ---\n",
      "Metadata: {'document_id': '26/2012/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2012-01-15', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=28010&Keyword=', 'domain': 'Vệ sinh an toàn và dinh dưỡng', 'Chương': 'III', 'location_detail': 'Chương III: QUY ĐỊNH ĐỐI VỚI CÁC CƠ SỞ SẢN XUẤT, KINH DOANH THỰC PHẨM...', 'start_index_in_main': 8428}\n",
      "Nội dung (300 ký tự đầu): Chương III QUY ĐỊNH ĐỐI VỚI CÁC CƠ SỞ SẢN XUẤT, KINH DOANH THỰC PHẨM THUỘC ĐỐI TƯỢNG KHÔNG PHẢI CẤP GIẤY CHỨNG NHẬN Điều 9. Các cơ sở thuộc đối tượng không phải cấp Giấy chứng nhận Các cơ sở sản xuất, kinh doanh thực phẩm chức năng, thực phẩm tăng cường vi chất dinh dưỡng, phụ gia thực phẩm, chất hỗ...\n"
     ]
    }
   ],
   "source": [
    "# --- Kiểm tra Cuối cùng ---\n",
    "logging.info(\"--- Kiểm tra cuối cùng ---\")\n",
    "# Kiểm tra lại sự tồn tại của file index và các thành phần cần thiết\n",
    "faiss_file_check = Path(faiss_index_path).joinpath(\"index.faiss\")\n",
    "pkl_file_check = Path(faiss_index_path).joinpath(\"index.pkl\")\n",
    "\n",
    "if embeddings and FAISS and faiss_file_check.exists() and pkl_file_check.exists():\n",
    "    try:\n",
    "        logging.info(f\"Đang tải lại index FAISS từ '{faiss_index_path}' để kiểm tra...\")\n",
    "        # Luôn cần embeddings khi load, và cờ allow_dangerous_deserialization\n",
    "        vectordb_check = FAISS.load_local(\n",
    "            folder_path=faiss_index_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        final_count = vectordb_check.index.ntotal # Lấy số lượng vector\n",
    "        logging.info(f\"Index FAISS tải thành công. Tổng số đoạn (chunks/vectors): {final_count}\")\n",
    "\n",
    "        # Thử truy vấn nếu có vector\n",
    "        if final_count > 0:\n",
    "            logging.info(\"Thực hiện truy vấn thử nghiệm...\")\n",
    "            query = \"Điều kiện cấp giấy chứng nhận thực phẩm xuất khẩu\"\n",
    "            start_query_time = time.time()\n",
    "            # k là số kết quả trả về\n",
    "            # Thêm tham số fetch_k để lấy nhiều hơn và lọc lại sau (có thể cải thiện chất lượng)\n",
    "            docs = vectordb_check.similarity_search(query, k=5, fetch_k=20)\n",
    "            end_query_time = time.time()\n",
    "            logging.info(f\"Truy vấn hoàn tất sau {end_query_time - start_query_time:.3f} giây.\")\n",
    "\n",
    "            if docs:\n",
    "                logging.info(f\"Truy vấn thử '{query}' tìm thấy {len(docs)} kết quả (top 5):\")\n",
    "                for i, doc in enumerate(docs):\n",
    "                    print(f\"\\n--- Kết quả {i+1} ---\")\n",
    "                    print(f\"Metadata: {doc.metadata}\")\n",
    "                    # In nội dung cẩn thận hơn\n",
    "                    content_preview = str(doc.page_content)[:300] if hasattr(doc, 'page_content') else \"[Nội dung không hợp lệ]\"\n",
    "                    print(f\"Nội dung (300 ký tự đầu): {content_preview}...\")\n",
    "            else:\n",
    "                logging.info(f\"Truy vấn thử '{query}' không tìm thấy kết quả nào.\")\n",
    "        else:\n",
    "            logging.info(\"Index FAISS không có vector nào để thực hiện truy vấn.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi trong quá trình kiểm tra cuối cùng với FAISS: {e}\", exc_info=True)\n",
    "else:\n",
    "    logging.warning(f\"Không tìm thấy index FAISS đã lưu ({faiss_index_path}) hoặc lỗi embedding/FAISS. Không thể kiểm tra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2712d058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 04:23:45,363 - INFO - --- Bắt đầu kiểm tra và truy xuất từ FAISS ---\n",
      "2025-04-21 04:23:45,379 - INFO - Đang tải lại index FAISS từ 'db_faiss_phapluat_yte_full_final'...\n",
      "2025-04-21 04:23:45,507 - INFO - Index FAISS tải thành công. Tổng số đoạn (chunks/vectors): 15498\n",
      "2025-04-21 04:23:45,518 - INFO - \n",
      "--- Bắt đầu thực hiện truy vấn ---\n",
      "2025-04-21 04:23:45,520 - INFO - \n",
      "[Truy vấn 1: similarity_search(k=4)]\n",
      "2025-04-21 04:23:45,563 - INFO - Thời gian truy vấn: 0.043 giây\n",
      "2025-04-21 04:23:45,563 - INFO - \n",
      "[Truy vấn 2: similarity_search_with_score(k=3)]\n",
      "2025-04-21 04:23:45,603 - INFO - Thời gian truy vấn: 0.041 giây\n",
      "2025-04-21 04:23:45,605 - INFO - \n",
      "[Truy vấn 3: max_marginal_relevance_search(k=4, fetch_k=20)]\n",
      "2025-04-21 04:23:45,651 - INFO - Thời gian truy vấn: 0.046 giây\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu hỏi: Hồ sơ đề nghị cấp giấy chứng nhận thực phẩm xuất khẩu gồm những gì?\n",
      "\n",
      "Kết quả (Top 4):\n",
      "\n",
      "--- Kết quả 1 ---\n",
      "  Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '4', 'location_detail': 'Điều 4: Hồ sơ đề nghị cấp giấy chứng nhận...', 'start_index_in_main': 2378}\n",
      "  Nội dung: Điều 4. Hồ sơ đề nghị cấp giấy chứng nhận Hồ sơ đề nghị cấp giấy chứng nhận cho 01 (mộ t) lô hàng xuất khẩu hoặc một cơ sở sản xuất thực phẩm xuất khẩu gồm: 1. Đơn đề nghị cấp giấy chứng nhận theo mẫu quy định tại Phụ lục ban hành kèm theo Thông tư này; 2. Giấy chứng nhận cơ sở đủ điều kiện an toàn ...\n",
      "\n",
      "--- Kết quả 2 ---\n",
      "  Metadata: {'document_id': '47/2014/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2015-02-15', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=43946&Keyword=', 'domain': '', 'Chương': 'I', 'Điều': '1', 'location_detail': 'Chương I: HỒ SƠ, THỦ TỤC VÀ PHÂN CẤP CẤP GIẤY CHỨNG NHẬN... -> Điều 1: Hồ sơ cấp Giấy chứng nhận...', 'start_index_in_main': 135}\n",
      "  Nội dung: Điều 1. Hồ sơ cấp Giấy chứng nhận Hồ sơ đề nghị cấp Giấy chứng nhận cơ sở đủ điều kiện an toàn thực phẩm (sau đây gọi tắt là Giấy chứng nhậ n) đối với cơ sở kinh doanh dịch vụ ăn uống (sau đây gọi tắt là cơ sở) được đóng thành 01 bộ theo quy định tại Điều 36 Luật an toàn thực phẩm, gồm các giấy tờ s...\n",
      "\n",
      "--- Kết quả 3 ---\n",
      "  Metadata: {'document_id': '26/2012/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2012-01-15', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=28010&Keyword=', 'domain': 'Vệ sinh an toàn và dinh dưỡng', 'Chương': 'II', 'Điều': '3', 'location_detail': 'Chương II: HỒ SƠ, THỦ TỤC VÀ THẨM QUYỀN CẤP GIẤY CHỨNG NHẬN CƠ SỞ ĐỦ ĐIỀU KIỆN AN TOÀN THỰC PHẨM... -> Điều 3: Hồ sơ xin cấp Giấy chứng nhận...', 'start_index_in_main': 1146}\n",
      "  Nội dung: Điều 3. Hồ sơ xin cấp Giấy chứng nhận Hồ sơ xin cấp Giấy chứng nhận được đóng thành 01 quyển, gồm các giấy tờ sau: 1. Đơn đề nghị cấp Giấy chứng nhận cơ sở đủ điều kiện an toàn thực phẩm (theo Mẫu 1 được ban hành kèm theo Thông tư nà y). 2. Giấy chứng nhận đăng ký kinh doanh có đăng ký ngành nghề ki...\n",
      "\n",
      "--- Kết quả 4 ---\n",
      "  Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '3', 'Khoản': '2', 'Điểm': 'đ', 'location_detail': 'Điều 3: Giấy chứng nhận đối với thực phẩm xuất khẩu... -> Khoản 2 -> Điểm đ', 'start_index_in_main': 1523}\n",
      "  Nội dung: Số và thời hạn hiệu lực của giấy chứng nhận cơ sở đủ điều kiện an toàn thực phẩm hoặc tương đương đối với giấy chứng nhận liên quan đến cơ sở sản xuất thực phẩm; e) Tên và địa chỉ của tổ chức, cá nhân xuất khẩu; cơ sở sản xuất; g) Căn cứ trên phiếu kiểm nghiệm của lô sản phẩm thực phẩm xuất khẩu, xá...\n",
      "Câu hỏi: Thẩm quyền thu hồi giấy chứng nhận?\n",
      "\n",
      "Kết quả (Top 3):\n",
      "\n",
      "--- Kết quả 1 ---\n",
      "  Score: 25.4101\n",
      "  Metadata: {'document_id': '08/2025/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2025-03-07', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=176041&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '7', 'location_detail': 'Điều 7: Thẩm quyền, trình tự thu hồi giấy chứng nhận...', 'start_index_in_main': 6869}\n",
      "  Nội dung: Điều 7. Thẩm quyền, trình tự thu hồi giấy chứng nhận 1. Bộ Y tế (Cục An toàn thực phẩ m) ban hành văn bản thu hồi giấy chứng nhận và gửi cho tổ chức, cá nhân xuất khẩu đã được cấp giấy chứng nhận; đồng thời đăng tải thông tin trên trang thông tin điện tử của Cục và gửi thông báo đến cơ quan hải quan...\n",
      "\n",
      "--- Kết quả 2 ---\n",
      "  Score: 28.1559\n",
      "  Metadata: {'document_id': '08/2022/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2022-10-20', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=159339&Keyword=', 'domain': 'Quản lý dược', 'Chương': 'V', 'Điều': '40', 'location_detail': 'Chương V: THU HỒI GIẤY ĐĂNG KÝ LƯU HÀNH, NGỪNG NHẬN HỒ SƠ CẤP, GIA HẠN GIẤY ĐĂNG KÝ LƯU HÀNH... -> Điều 40: Thẩm quyền, thủ tục thu hồi giấy đăng ký lưu hành thuốc, nguyên liệu làm thuốc...', 'start_index_in_main': 109887}\n",
      "  Nội dung: Điều 40. Thẩm quyền, thủ tục thu hồi giấy đăng ký lưu hành thuốc, nguyên liệu làm thuốc 1. Thẩm quyền thu hồi và trách nhiệm thông báo thu hồi giấy đăng ký lưu hành: a) Cục Quản lý Dược thu hồi giấy đăng ký lưu hành thuốc, nguyên liệu làm thuốc thuộc các trường hợp quy định tại khoản 1 Điều 58 Luật ...\n",
      "\n",
      "--- Kết quả 3 ---\n",
      "  Score: 28.7003\n",
      "  Metadata: {'document_id': '06/2011/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2011-04-01', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=26157&Keyword=', 'domain': '', 'Chương': 'IX', 'Điều': '47', 'Khoản': '3', 'location_detail': 'Chương IX: KIỂM TRA, THANH TRA VÀ XỬ LÝ VI PHẠM... -> Điều 47: Các trường hợp tạm ngừng tiếp nhận hồ sơ công bố sản phẩm mỹ phẩm, hồ sơ đăng ký quảng cáo mỹ phẩm, ... -> Khoản 3', 'start_index_in_main': 58597}\n",
      "  Nội dung: 3. Cơ quan quản lý nhà n ước có thẩm quyền sẽ xem xét tạm ngừng tiếp nhận hồ sơ công bố sản phẩm mỹ phẩm, hồ sơ đăng ký quảng cáo mỹ phẩm, tổ chức hội thảo, sự kiện giới thiệu mỹ phẩm đối với tổ chức, cá nhân không nộp báo cáo kết quả hoạt động sản xuất kinh doanh hàng năm theo quy định. Hết thời hạ...\n",
      "Câu hỏi: Nội dung giấy chứng nhận cần có thông tin gì?\n",
      "\n",
      "Kết quả (Top 4 - Đã lọc MMR):\n",
      "\n",
      "--- Kết quả 1 ---\n",
      "  Metadata: {'document_id': '18/2019/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2019-07-17', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=137245&Keyword=', 'domain': 'An toàn thực phẩm', 'Điều': '4', 'Khoản': '2', 'location_detail': 'Điều 4 -> Khoản 2', 'start_index_in_main': 9114}\n",
      "  Nội dung: 2. Yêu cầu đối với nội dung của giấy chứng nhận, chứng nhận tương đương quy định tại các Điểm a, b và c Khoản 1 Điều này bao gồm các thông tin sau: a) Tên cơ quan, tổ chức có thẩm quyền cấp; b) Ngày cấp; c) Thời hạn hiệu lực (trong trường hợp giấy chứng nhận không ghi thời hạn hiệu lực thì phải có t...\n",
      "\n",
      "--- Kết quả 2 ---\n",
      "  Metadata: {'document_id': '22/2011/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2011-07-25', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=26730&Keyword=', 'domain': '', 'Chương': 'III', 'Điều': '15', 'Khoản': '5', 'Điểm': 'b', 'location_detail': 'Chương III: HOẠT ĐỘNG CHÍNH CỦA KHOA DƯỢC... -> Điều 15: Theo dõi và quản lý nhập, xuất thuốc... -> Khoản 5 -> Điểm b', 'start_index_in_main': 17680}\n",
      "  Nội dung: b) Nội dung bàn giao bao gồm sổ sách, giấy tờ, chứng từ, đối chiếu với thực tế về số lượng và chất lượng, những việc cần theo dõi và hoàn thành tiếp (ghi rõ chức trách, nhiệm vụ cụ thể); c) Biên bản bàn giao ghi rõ ràng, có sự chứng kiến và ký duyệt của Lãnh đạo cấp trên trực tiếp của người bàn giao...\n",
      "\n",
      "--- Kết quả 3 ---\n",
      "  Metadata: {'document_id': '11/2021/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2021-08-19', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=149192&Keyword=', 'domain': 'Quản lý dược', 'Chương': 'III', 'Điều': '15', 'Khoản': '5', 'location_detail': 'Chương III: HỒ SƠ ĐỀ NGHỊ CẤP, GIA HẠN, THAY ĐỔI, BỔ SUNG GIẤY ĐĂNG KÝ LƯU HÀNH VẮC XIN... -> Điều 15: Quy định đối với các tài liệu trong hồ sơ đề nghị cấp, gia hạn, thay đổi, bổ sung giấy đăng ký lưu h... -> Khoản 5', 'start_index_in_main': 16351}\n",
      "  Nội dung: Phiếu kiểm nghiệm phải bao gồm các thông tin sau: thông tin hành chính (tên, địa chỉ cơ sở sản xuất, tên và chữ ký của người được giao trách nhiệm, ngày ký phiếu kiểm nghiệ m) và thông tin về mẫu vắc xin, nguyên liệu làm vắc xin (tên sản phẩm, số lô, hạn dùng, tiêu chuẩn chất lượng áp dụng, chỉ tiêu...\n",
      "\n",
      "--- Kết quả 4 ---\n",
      "  Metadata: {'document_id': '08/2022/TT-BYT', 'document_type': 'Thông tư', 'effective_date': '2022-10-20', 'source_link': 'https://vbpl.vn/boyte/Pages/vbpq-toanvan.aspx?ItemID=159339&Keyword=', 'domain': 'Quản lý dược', 'Chương': 'III', 'Mục': '1', 'Điều': '22', 'Khoản': '3', 'location_detail': 'Chương III: HỒ SƠ ĐĂNG KÝ THUỐC, NGUYÊN LIỆU LÀM THUỐC... -> Mục 1: QUY ĐỊNH CHUNG VỀ HỒ SƠ ĐỀ NGHỊ CẤP, GIA HẠN, THAY ĐỔI, BỔ SUNG GIẤY ĐĂNG KÝ LƯU HÀNH THUỐC, NGUYÊN ... -> Điều 22: Quy định đối với các tài liệu trong hồ sơ đề nghị cấp, gia hạn, thay đổi, bổ sung giấy đăng ký lưu h... -> Khoản 3', 'start_index_in_main': 46183}\n",
      "  Nội dung: 3. Giấy tờ pháp lý: a) Bản chính phải có đầy đủ chữ ký, tên người ký và dấu xác nhận của cơ quan có thẩm quyền của nước cấp hoặc bản sao có chứng thực phải do cơ quan, tổ chức có thẩm quyền của Việt Nam chứng thực theo quy định của pháp luật Việt Nam về chứng thực bản sao từ bản chính. Trong trường ...\n"
     ]
    }
   ],
   "source": [
    "import time # Thêm import time nếu chưa có\n",
    "\n",
    "# --- Tải Index và Truy xuất ---\n",
    "logging.info(\"--- Bắt đầu kiểm tra và truy xuất từ FAISS ---\")\n",
    "\n",
    "# Kiểm tra các thành phần cần thiết và sự tồn tại của file index\n",
    "faiss_file_check = Path(faiss_index_path).joinpath(\"index.faiss\")\n",
    "pkl_file_check = Path(faiss_index_path).joinpath(\"index.pkl\")\n",
    "vectordb_check = None # Khởi tạo là None\n",
    "\n",
    "if embeddings and FAISS and faiss_file_check.exists() and pkl_file_check.exists():\n",
    "    try:\n",
    "        logging.info(f\"Đang tải lại index FAISS từ '{faiss_index_path}'...\")\n",
    "        vectordb_check = FAISS.load_local(\n",
    "            folder_path=faiss_index_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True # Cần thiết cho FAISS\n",
    "        )\n",
    "        final_count = vectordb_check.index.ntotal\n",
    "        logging.info(f\"Index FAISS tải thành công. Tổng số đoạn (chunks/vectors): {final_count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi tải index FAISS để truy xuất: {e}\", exc_info=True)\n",
    "        vectordb_check = None # Đặt lại nếu lỗi\n",
    "else:\n",
    "    logging.warning(f\"Không tìm thấy index FAISS đã lưu ({faiss_index_path}) hoặc lỗi embedding/FAISS. Không thể truy xuất.\")\n",
    "\n",
    "# --- Thực hiện truy vấn nếu tải index thành công ---\n",
    "if vectordb_check and vectordb_check.index.ntotal > 0:\n",
    "    logging.info(\"\\n--- Bắt đầu thực hiện truy vấn ---\")\n",
    "\n",
    "    # === Ví dụ 1: Similarity Search cơ bản ===\n",
    "    query1 = \"Hồ sơ đề nghị cấp giấy chứng nhận thực phẩm xuất khẩu gồm những gì?\"\n",
    "    k1 = 4 # Lấy 4 kết quả\n",
    "    logging.info(f\"\\n[Truy vấn 1: similarity_search(k={k1})]\")\n",
    "    print(f\"Câu hỏi: {query1}\")\n",
    "    start_time = time.time()\n",
    "    results1 = vectordb_check.similarity_search(query1, k=k1)\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Thời gian truy vấn: {end_time - start_time:.3f} giây\")\n",
    "\n",
    "    print(f\"\\nKết quả (Top {len(results1)}):\")\n",
    "    for i, doc in enumerate(results1):\n",
    "        print(f\"\\n--- Kết quả {i+1} ---\")\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        print(f\"  Nội dung: {doc.page_content[:300]}...\") # In 300 ký tự đầu\n",
    "\n",
    "    # === Ví dụ 2: Similarity Search với Điểm số ===\n",
    "    query2 = \"Thẩm quyền thu hồi giấy chứng nhận?\"\n",
    "    k2 = 3 # Lấy 3 kết quả\n",
    "    logging.info(f\"\\n[Truy vấn 2: similarity_search_with_score(k={k2})]\")\n",
    "    print(f\"Câu hỏi: {query2}\")\n",
    "    start_time = time.time()\n",
    "    results2 = vectordb_check.similarity_search_with_score(query2, k=k2)\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Thời gian truy vấn: {end_time - start_time:.3f} giây\")\n",
    "\n",
    "    print(f\"\\nKết quả (Top {len(results2)}):\")\n",
    "    for i, (doc, score) in enumerate(results2):\n",
    "        print(f\"\\n--- Kết quả {i+1} ---\")\n",
    "        print(f\"  Score: {score:.4f}\") # In điểm số (Lưu ý: điểm thấp hơn thường tốt hơn với FAISS/L2)\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        print(f\"  Nội dung: {doc.page_content[:300]}...\")\n",
    "\n",
    "    # === Ví dụ 3: Max Marginal Relevance Search (MMR) ===\n",
    "    # Lấy kết quả đa dạng hơn\n",
    "    query3 = \"Nội dung giấy chứng nhận cần có thông tin gì?\"\n",
    "    k3 = 4 # Lấy 4 kết quả cuối cùng\n",
    "    fetch_k3 = 20 # Lấy 20 kết quả ban đầu để chọn lọc\n",
    "    logging.info(f\"\\n[Truy vấn 3: max_marginal_relevance_search(k={k3}, fetch_k={fetch_k3})]\")\n",
    "    print(f\"Câu hỏi: {query3}\")\n",
    "    start_time = time.time()\n",
    "    results3 = vectordb_check.max_marginal_relevance_search(query3, k=k3, fetch_k=fetch_k3)\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Thời gian truy vấn: {end_time - start_time:.3f} giây\")\n",
    "\n",
    "    print(f\"\\nKết quả (Top {len(results3)} - Đã lọc MMR):\")\n",
    "    for i, doc in enumerate(results3):\n",
    "        print(f\"\\n--- Kết quả {i+1} ---\")\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        print(f\"  Nội dung: {doc.page_content[:300]}...\")\n",
    "\n",
    "elif vectordb_check and vectordb_check.index.ntotal == 0:\n",
    "    logging.warning(\"Index FAISS đã được tải nhưng không chứa vector nào. Không thể truy vấn.\")\n",
    "else:\n",
    "    logging.warning(\"Không thể tải Index FAISS hoặc index rỗng. Bỏ qua bước truy vấn.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
